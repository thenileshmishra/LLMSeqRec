{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(rating_path, movie_path):\n",
    "    \"\"\"\n",
    "    Load rating and movie CSV files.\n",
    "    \"\"\"\n",
    "    ratings = pd.read_csv(rating_path, usecols=['userId', 'movieId', 'rating', 'timestamp'])\n",
    "    movies = pd.read_csv(movie_path, usecols=['movieId', 'title', 'genres'])\n",
    "    return ratings, movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def filter_ratings(ratings, min_rating=3.0):\n",
    "    \"\"\"\n",
    "    Filter ratings to include only those >= min_rating.\n",
    "    \"\"\"\n",
    "    filtered = ratings[ratings['rating'] >= min_rating].copy()\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_item_metadata(movies):\n",
    "    \"\"\"\n",
    "    Build item metadata from movie title and genres.\n",
    "    Return a dictionary {item_id: \"title - genres\"} and a DataFrame for saving.\n",
    "    \"\"\"\n",
    "    # Example: \"Toy Story (1995) - Genres: Animation, Children, Comedy\"\n",
    "    item_metadata_dict = {}\n",
    "    for row in movies.itertuples():\n",
    "        movie_id = row.movieId\n",
    "        title = row.title if pd.notnull(row.title) else \"Unknown Title\"\n",
    "        genres = row.genres if pd.notnull(row.genres) else \"Unknown\"\n",
    "        # Clean genres if needed (e.g. split by '|')\n",
    "        genres_str = \", \".join(genres.split('|')) if genres != \"(no genres listed)\" else \"N/A\"\n",
    "        item_metadata_dict[movie_id] = f\"{title} - Genres: {genres_str}\"\n",
    "    \n",
    "    # Build a DataFrame to save\n",
    "    meta_df = pd.DataFrame({\n",
    "        'movieId': list(item_metadata_dict.keys()),\n",
    "        'metadata': list(item_metadata_dict.values())\n",
    "    })\n",
    "    return item_metadata_dict, meta_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_sequences(ratings, max_seq_len=150):\n",
    "    \"\"\"\n",
    "    Group by user, sort by timestamp, and create sequences.\n",
    "    Return a dict of {user_id: [list_of_item_ids_in_order]}.\n",
    "    \"\"\"\n",
    "    # Sort by (userId, timestamp)\n",
    "    ratings_sorted = ratings.sort_values(by=['userId', 'timestamp'])\n",
    "    \n",
    "    # Group by userId\n",
    "    user_sequences = {}\n",
    "    for user_id, group in ratings_sorted.groupby('userId'):\n",
    "        # Sort within the group by ascending timestamp\n",
    "        item_list = group['movieId'].tolist()\n",
    "        \n",
    "        # If the user has more than max_seq_len interactions, keep the last max_seq_len\n",
    "        if len(item_list) > max_seq_len:\n",
    "            item_list = item_list[-max_seq_len:]\n",
    "        \n",
    "        user_sequences[user_id] = item_list\n",
    "    \n",
    "    return user_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_one_out_split(user_sequences):\n",
    "    \"\"\"\n",
    "    For each user's sequence:\n",
    "      - Last item is test\n",
    "      - Second-last item is validation\n",
    "      - Everything else is training\n",
    "    Return dictionaries: train_seqs, val_seqs, test_seqs\n",
    "    \"\"\"\n",
    "    train_seqs = {}\n",
    "    val_seqs = {}\n",
    "    test_seqs = {}\n",
    "    \n",
    "    for user, seq in user_sequences.items():\n",
    "        if len(seq) < 2:\n",
    "            # Not enough interactions for val/test\n",
    "            # We'll treat everything as train or handle edge cases as needed\n",
    "            train_seqs[user] = seq\n",
    "            val_seqs[user] = []\n",
    "            test_seqs[user] = []\n",
    "        else:\n",
    "            test_item = seq[-1:]\n",
    "            val_item = seq[:-1]\n",
    "            train_items = seq[:]\n",
    "            train_seqs[user] = train_items\n",
    "            val_seqs[user] = val_item\n",
    "            test_seqs[user] = test_item\n",
    "    \n",
    "    return train_seqs, val_seqs, test_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(seq, max_len=150, pad_val=0):\n",
    "    \"\"\"\n",
    "    Pad a sequence to max_len with pad_val.\n",
    "    \"\"\"\n",
    "    if len(seq) < max_len:\n",
    "        seq = [pad_val] * (max_len - len(seq)) + seq\n",
    "    return seq[-max_len:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_id_mappings(user_sequences, item_metadata_dict):\n",
    "    \"\"\"\n",
    "    Build contiguous ID mappings for users and items.\n",
    "    Return:\n",
    "      - user2idx, item2idx\n",
    "      - idx2user, idx2item\n",
    "    \"\"\"\n",
    "    unique_users = sorted(list(user_sequences.keys()))\n",
    "    unique_items = sorted(list(item_metadata_dict.keys()))\n",
    "    \n",
    "    user2idx = {u: i for i, u in enumerate(unique_users)}\n",
    "    item2idx = {m: i for i, m in enumerate(unique_items)}\n",
    "    \n",
    "    idx2user = {i: u for u, i in user2idx.items()}\n",
    "    idx2item = {i: m for m, i in item2idx.items()}\n",
    "    \n",
    "    return user2idx, item2idx, idx2user, idx2item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(seq, max_len=150, pad_val=0):\n",
    "    \"\"\"\n",
    "    Pad or truncate a sequence to a fixed length.\n",
    "    Pads on the left (like typical NLP settings).\n",
    "    \"\"\"\n",
    "    if len(seq) >= max_len:\n",
    "        return seq[-max_len:]\n",
    "    return [pad_val] * (max_len - len(seq)) + seq\n",
    "\n",
    "\n",
    "def convert_and_pad_splits(train_seqs, val_seqs, test_seqs, user2idx, item2idx, max_seq_len=150):\n",
    "    \"\"\"\n",
    "    Convert user/item IDs to indices, pad sequences, and return DataFrames.\n",
    "    Format:\n",
    "      - Train: [user_id] + padded_seq\n",
    "      - Val/Test: [user_id] + padded_seq + label\n",
    "    \"\"\"\n",
    "    train_data = []\n",
    "    val_data = []\n",
    "    test_data = []\n",
    "\n",
    "    # Train\n",
    "    for user, train_items in train_seqs.items():\n",
    "        if user not in user2idx:\n",
    "            continue\n",
    "        u_idx = user2idx[user]\n",
    "        train_items_idx = [item2idx[i] for i in train_items if i in item2idx]\n",
    "        if not train_items_idx:\n",
    "            continue\n",
    "        train_items_idx = pad_sequence(train_items_idx, max_len=max_seq_len, pad_val=0)\n",
    "        train_data.append([u_idx] + train_items_idx)\n",
    "\n",
    "    # Validation\n",
    "    for user, val_items in val_seqs.items():\n",
    "        if user not in user2idx:\n",
    "            continue\n",
    "        u_idx = user2idx[user]\n",
    "        val_items_idx = [item2idx[i] for i in val_items if i in item2idx]\n",
    "        if len(val_items_idx) < 2:\n",
    "            continue\n",
    "        input_seq = val_items_idx[:-1]\n",
    "        label = val_items_idx[-1]\n",
    "        input_seq = pad_sequence(input_seq, max_len=max_seq_len, pad_val=0)\n",
    "        val_data.append([u_idx] + input_seq + [label])\n",
    "\n",
    "    # Test\n",
    "    for user, test_items in test_seqs.items():\n",
    "        if user not in user2idx:\n",
    "            continue\n",
    "        u_idx = user2idx[user]\n",
    "        test_items_idx = [item2idx[i] for i in test_items if i in item2idx]\n",
    "        if len(test_items_idx) < 2:\n",
    "            continue\n",
    "        input_seq = test_items_idx[:-1]\n",
    "        label = test_items_idx[-1]\n",
    "        input_seq = pad_sequence(input_seq, max_len=max_seq_len, pad_val=0)\n",
    "        test_data.append([u_idx] + input_seq + [label])\n",
    "\n",
    "    # Build DataFrames\n",
    "    train_df = pd.DataFrame(train_data)\n",
    "    val_df = pd.DataFrame(val_data)\n",
    "    test_df = pd.DataFrame(test_data)\n",
    "\n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Define file paths\n",
    "    rating_path = \"../data/rawdata/rating.csv\"\n",
    "    movie_path = \"../data/rawdata/movie.csv\"\n",
    "    processed_dir = \"../data/processed\"\n",
    "    os.makedirs(processed_dir, exist_ok=True)\n",
    "    \n",
    "    # 1. Load Data\n",
    "    ratings, movies = load_data(rating_path, movie_path)\n",
    "    \n",
    "    # 2. Filter Ratings\n",
    "    ratings = filter_ratings(ratings, min_rating=3.0)\n",
    "    \n",
    "    user_count = ratings['userId'].value_counts()\n",
    "    top_users = user_count.head(10000).index\n",
    "    ratings = ratings[ratings['userId'].isin(top_users)]\n",
    "    \n",
    "    # 3. Build Item Metadata\n",
    "    item_metadata_dict, meta_df = build_item_metadata(movies)\n",
    "    \n",
    "    # 4. Create User Sequences\n",
    "    user_sequences = create_user_sequences(ratings, max_seq_len=150)\n",
    "    \n",
    "    # 5. Leave-One-Out Split\n",
    "    train_seqs, val_seqs, test_seqs = leave_one_out_split(user_sequences)\n",
    "    \n",
    "    # 6. Build ID Mappings\n",
    "    user2idx, item2idx, idx2user, idx2item = build_id_mappings(user_sequences, item_metadata_dict)\n",
    "    \n",
    "    # 7. Convert & Pad Splits\n",
    "    train_df, val_df, test_df = convert_and_pad_splits(train_seqs, val_seqs, test_seqs,\n",
    "                                                       user2idx, item2idx, max_seq_len=150)\n",
    "    \n",
    "    # 8. Save Outputs\n",
    "    #   8a. Sequences\n",
    "    train_df.to_csv(os.path.join(processed_dir, 'train_sequences.csv'), index=False, header=False)\n",
    "    val_df.to_csv(os.path.join(processed_dir, 'val_sequences.csv'), index=False, header=False)\n",
    "    test_df.to_csv(os.path.join(processed_dir, 'test_sequences.csv'), index=False, header=False)\n",
    "    \n",
    "    #   8b. Metadata\n",
    "    meta_df.to_csv(os.path.join(processed_dir, 'item_metadata.csv'), index=False)\n",
    "    \n",
    "    #   8c. Mappings\n",
    "    #       We'll store user2idx and item2idx in a simple DataFrame format\n",
    "    user_mapping_df = pd.DataFrame(list(user2idx.items()), columns=['original_user_id', 'mapped_id'])\n",
    "    item_mapping_df = pd.DataFrame(list(item2idx.items()), columns=['original_item_id', 'mapped_id'])\n",
    "    \n",
    "    user_mapping_df.to_csv(os.path.join(processed_dir, 'user_mapping.csv'), index=False)\n",
    "    item_mapping_df.to_csv(os.path.join(processed_dir, 'item_mapping.csv'), index=False)\n",
    "    \n",
    "    print(\"Data preprocessing complete. Files saved in:\", processed_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing complete. Files saved in: ../data/processed\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
